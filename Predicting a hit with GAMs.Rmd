---
title: "Predicting a hit with GAMs"
author: "Brandon Hoeft"
date: "February 25, 2018"
output:
  github_document:
    toc: TRUE
    toc_depth: 3
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(pryr) # mem_used() and object_size() functions to manage/understand memory usage.

```


## Overview

This writeup is being used to learn by applying generalized additive models, or GAMs for short, to MLB statcast batter data from 2017. Specifically, we'll be trying to predict whether a ball hit into play was a hit. This event can be represented a Bernoulli event, which we can model its likelihood as a function of a subset of predictors of interest about the batted ball event.  

## Load Statcast Dataset 

See the accompanying analysis, **statcast data with R** , on how I scraped and obtained batter data from MLB's Statcast system from much of the 2017 season. These data will be the basis of further analysis. 

The data extract is currently being stored on [AWS S3](https://aws.amazon.com/s3/).

```{r awsS3}
library(aws.s3)
library(feather)

# specify personal account keys as environment variables so I can read my s3 object(s) from AWS. 
# DO NOT SAVE KEY in code or render in output!!!! Could compromise AWS account. 
# Note to self my key and secret last gen from October 2017. 
#Sys.setenv("AWS_ACCESS_KEY_ID" = "",
#           "AWS_SECRET_ACCESS_KEY" = "")
# items: part number, parent, catalogue, attributes/values.

statcast17 <- s3read_using(FUN = read_feather, 
                      object = "statcast_batter_data.feather", 
                      bucket = "baseball-project")

```

## Basic Description of the Data

There are `r ncol(statcast17)` variables in these data, and range from the gamedays of `r min(statcast17$game_date)` to `r max(statcast17$game_date)`.

These data take up a lot of space on disk, specifically `r object_size(statcast17)`MB. As we can see by the number of rows below, it probably makes to use just a smaller subset of these data for analysis by randomly sampling from it. 

``` {r explore}
library(dplyr)

glimpse(statcast17)
```

### What events do we want?

As mentioned before, we want to predict hits using the sample space of events where any ball was hit into play. The *description* field helps explain some of the different types of situations captured in the dataset.

``` {r}

statcast17 %>%
    group_by(description) %>%
    summarize(total = n()) %>%
    mutate(proportion_of_total = round(total / sum(total), 2)) %>%
    arrange(desc(total)) %>%
    kable()
```

It looks like our situations of interest in the *description* field are prefixed by "hit_into". Let's check to ensure that the *events* associated with these make sense to use.

``` {r}

statcast17 %>%
    filter(description %in% c("hit_into_play", "hit_into_play_no_out", "hit_into_play_score")) %>%
    group_by(description, events) %>%
    summarize(total = n()) %>%
    mutate(proportion_of_total = round(total / sum(total), 2)) %>%
    arrange(description, desc(total))
```

Having looked at the types of events, it appears the 3 *description* categories relating to balls hit into play give covereage for the types of events we want to model. The only events I'll filter out for now are "sac_bunt" and "catcher_interf", as neither of these really relate to hitting all that much.

## Sample the data

We'll gloss over the exploratory data analysis for now, and get to modeling. First, we'll sample from the entire dataset to work with a more manageable, but representative subset for modeling the likelihood of getting a hit when the ball was batted into play. 

``` {r}
set.seed(54321)
sample_data <- statcast17 %>%
    # hit type data and complete cases. 
    filter(description %in% c("hit_into_play", "hit_into_play_no_out", "hit_into_play_score"),
           !events %in% c("sac_bunt", "catcher_interf")) %>%
    sample_n(size = 10000, replace = FALSE) %>%
    mutate(y_hit = factor(ifelse(events %in% c("single", "double", "triple", "home_run"),
                          "yes_hit",
                          "no_hit"), levels = c("no_hit", "yes_hit")))

sample_data %>%
    group_by(y_hit) %>%
    summarize(total = n()) %>%
    mutate(average = round(total / sum(total), 3))
```

We see that when the ball was hit into play for this sample of records, the batted ball landed for a hit approximately `r 100 * round(prop.table(table(sample_data$y_hit)), 3)[[2]]`% of the time. This is the outcome we are going to target in our model.

## Predictors 

Predictors we'll focus on for now to try and predict a hit are:

* **release speed**: the speed of the pitch in MPH
* **pitch type**: the type of pitch thrown.

``` {r echo = TRUE}
pitch_type_summary <- sample_data %>%
    group_by(pitch_type) %>%
    summarize(total = n()) %>%
    mutate(proportion_of_total = round(total / sum(total), 2),
           less_two_percent = ifelse(proportion_of_total < .05, TRUE, FALSE)) %>%
    arrange(desc(total)) 
pitch_type_summary %>% kable()

rare_pitch <- pitch_type_summary[pitch_type_summary$less_two_percent == TRUE, ]$pitch_type
```

* **p throws**: the throwing hand of the pitcher.
* **launch speed**: the speed of the ball of the bat in MPH
* **launch angle**: the angle of the ball's trajectory off the bat upon contact. 
* **balls**: the number of balls in the pitching count at time of event.
* **strikes**: the number of strikes in the pitching count at time of event. 

``` {r echo = FALSE}
sample_data %>%
    select(release_speed, pitch_type, p_throws, launch_angle, launch_speed, balls, strikes, y_hit) %>%
    glimpse()
```



## Data Pre-processing

From glimpsing at the predictors, we notice some are not yet ready for modeling. We'll get the data ready for modeling by: handling missing data, making sure predictors are typed appropriately, and simplifiying some of the categorical predictors to be more useful by aggregating sparse categories.

``` {r}
modeling_data <- sample_data %>%
    select(release_speed, pitch_type, p_throws, launch_angle, launch_speed, balls, strikes, y_hit) %>%
    mutate(pitch_type_clean = ifelse(pitch_type %in% rare_pitch, "Other", pitch_type),
           release_speed = as.numeric(release_speed)) %>%
    filter(complete.cases(.)) %>% # only keep records with non-missing data. 
    select(release_speed, pitch_type_clean, p_throws, launch_angle, launch_speed, balls, strikes, y_hit, -pitch_type)
    
glimpse(modeling_data)
```

## Fit a GAM Model using Cross-Validation

We'll use the `caret` library to develop a gam, which relies on the `gam` library. 

We'll use five-fold cross-validation. Additionally, for the `df` hyperparameter, "degrees freedom", we'll pass a grid of integer values. This model is using Hastie's package `GAM`. GAMs under this package are fit with smoothing splines. Hastie's book, [ISLR](http://www-bcf.usc.edu/~gareth/ISL/) explains these in detail. The effective degrees freedom or the $\lambda$ (lambda) parameter, penalizes the flexibility of each smoothing function for every x. 

$\lambda$ measures the total change in the smoothing function (the 2nd derivative) over the range of x. Small values of $\lambda$ will allow for very flexible curves (low bias, high variance). Higher values of $\lambda$ create flatter, smooth curves that approach a line (high bias, low variance). The goal is to find the best form of the smoother function that balances bias-variance tradeoff. 

$\lambda$ = 0: no penalty. the smoother function fits the Y ~ x relationship perfectly. 
$\lambda$ > 0:  higher penalty. increasingly larger values make the function fit the Y ~ x relationship more smoothly.

``` {r}
library(caret)
library(gam)

training_setup <- trainControl(method = "cv",
                               number = 5, #10-fold CV
                               savePredictions = TRUE,
                               classProbs = TRUE) 

degrees_freedom_grid = data.frame(df = seq(1, 20, by = 1))

set.seed(2018)
GAM_fit <- train(x = modeling_data[1:7],
                 y = modeling_data$y_hit,
                 method = 'gamSpline',
                 trControl = training_setup,
                 metric = "ROC",
                 tuneGrid = degrees_freedom_grid)
GAM_fit
plot(GAM_fit, se = TRUE, col = "blue")
```

We can also plot the relationship identified by the best GAM final fit model.

```{r}
plot(GAM_fit$finalModel, se = TRUE, col = "blue", all.terms = TRUE)
```